{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive notebook for the gpt_constructor package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "from statemachine import StateMachine \n",
    "from gpt_controller.config import DB_URL, CHATGPT_MODEL, PROMPT_PATH, SELF_TRAIN\n",
    "from gpt_controller.chat_gpt_interface.api_tools import InHouseAPI\n",
    "from gpt_controller.cognition.machine import GPTControllerMachine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Load the sqlalchemy models from database\n",
    "chatGPT_api = InHouseAPI()\n",
    "prompt_deck = chatGPT_api.get_prompt_deck()\n",
    "environment_deck = chatGPT_api.get_environment_deck()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. State Machine Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_machine = GPTControllerMachine()\n",
    "\n",
    "state_machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prompt benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for prompt_label, prompt in prompt_deck.items():\n",
    "    num_tokens = chatGPT_api.num_tokens_prompt(prompt)\n",
    "    print(\"Prompt: {} \\nNumber of tokens: {}\\n\".format(prompt_label, num_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for environment_label, environment in environment_deck.items():\n",
    "    num_tokens = chatGPT_api.num_tokens_prompt(environment)\n",
    "    print(\"Prompt: {} \\nNumber of tokens: {}\\n\".format(environment_label, num_tokens))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prompt testing text based\n",
    "\n",
    "Load and test output of specific completion context with:\n",
    "    \n",
    "```python\n",
    "chatGPT_api.request_completion()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(prompt_deck.keys())\n",
    "# TODO #2 Make this work\n",
    "chatGPT_api.request_completion(prompt_name=\"user_input_labelling.txt\", user_request=\"Hello, how are you?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self training [#7](https://github.com/andrei-calin-dragomir/gpt-robot-controller/issues/7)\n",
    "\n",
    "Self training is a method of training a model on its own output. This is done by using the output of the model as the input to the model. This is done iteratively to improve the model's performance on a specific task.\n",
    "\n",
    "### 1. Self-training text based\n",
    "\n",
    "#### Setup\n",
    "    \n",
    "- Set `SELF_TRAIN` to `True` in `config.py` to enable self-training.\n",
    "- Set `PERSISTENT_ENVIRONMENTS = True` in `config.py` to enable persistent environments.\n",
    "- Set `TOKEN_LIMIT` to your desired tokens to use in one run of self training.\n",
    "\n",
    "Self-training can potentially run indefinitely resulting in large token counts. To prevent this, set `TOKEN_LIMIT` to a value that you are comfortable with.\n",
    "\n",
    "#### Environment Descriptions\n",
    "\n",
    "This method allows you to create a root description of the environment you want the machine to train in.\n",
    "To do so, add an environment description as a `.txt` file in the `prompts/environment` folder in the root directory of the package.\n",
    "\n",
    "#### Usage\n",
    "```python\n",
    "GPTControllerMachine().self_train(environment=\"environment_name.txt\")\n",
    "```\n",
    "\n",
    "#### Inner workings\n",
    "This will generate a state machine with a Spawning state.\n",
    "Whenever the model is in the Idle state:\n",
    "    If `TOKEN_LIMIT` is reached, the model will go to the Finish state and then shut down.\n",
    "    Otherwise, it will go to Spawning state and generate a new environment or new task to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_deck.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPTControllerMachine().self_train(environment=\"environment_name.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
