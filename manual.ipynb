{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMPORARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complete',\n",
       " 'conclusion',\n",
       " 'function_content',\n",
       " 'function_name',\n",
       " 'get_context',\n",
       " 'id',\n",
       " 'pause',\n",
       " 'print_conclusion',\n",
       " 'start',\n",
       " 'start_time',\n",
       " 'status',\n",
       " 'stop_time',\n",
       " 'total_time']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_controller.util.models import *\n",
    "method_list = [method for method in dir(Task) if method.startswith('_') is False]\n",
    "list(method_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "- [ ] make function to check a set of sentences with a predefined label through the system and see if it gives the correct output.\n",
    "- [ ] make database folder with one .csv file for each run of the system that is saved when closing the system no matter what error occured.\n",
    "- [ ] If the system reproduces a learned function, it should take the current context into account when adapting the function. But the decision_making context as well as the acting() context are called with the learned function context\n",
    "- [ ] implement the process of calling a learned function. If the system starts to reproduce a learned function, whenever there is a function call comprised of a code sequence generated in a single task, tell chatGPT to adapt that function based on the current context.\n",
    "- [ ] add simple functionality to each acting module\n",
    "- [ ] finish `act()` function\n",
    "- [ ] finish memorization of new task sequences\n",
    "    - [ ] `act()` function triggers a new learning task to be added to the stack\n",
    "    - [ ] `make_decision()` calls the finalization of the top learned task based on querrying the system if it thinks it is done with the task.\n",
    "\n",
    "- [ ] make prompt tester for `function_similarity.txt`.\n",
    "\n",
    "If time allows:\n",
    "- [ ] Expensive but fast workaround for memorizing function calls with arguments. Instead of trying to give chatGPT the json schema of the newly created function, just save the code snippet generated and, when trying to reproduce a task that contains a function call, just run the code snippet with the adapted variables inputted by chatGPT and continue in the function task sequence with the new task.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do presentation\n",
    "\n",
    "Use `przi presentation` https://prezi.com/p/create-prezi/\n",
    "- [ ] make a mapping of the system\n",
    "- [ ] 1: I wanted to approach the problem of zero-shot action generation for novel as well as known tasks.\n",
    "- [ ] 2: chatGPT through recent works (such as microsoft and other examples of papers you read about it) has showcased reasoning capabilities through natural language based input.\n",
    "- [ ] 3: Talk about ReAct design of the system\n",
    "- [ ] 4: Talk about the overview state machine of the system\n",
    "- [ ] 5: Present the cognition module and its design (give list of functions such as recalling, memorizing, as well as labelling and decision making)\n",
    "    - Talk about the what is being leveraged on chatGPT and why.\n",
    "- [ ] 6: Present the acting modules as a collective general concept\n",
    "- [ ] 7: Present the memorization module and its benefits\n",
    "- [ ] 8: Present the decision making module and its design with a focus on what is leveraged on chatGPT\n",
    "\n",
    "Finalize:\n",
    "- [ ] : Optimizations that I see possible in the future are:\n",
    "    - [ ] : Creating a pseudolanguage for the ReAct system that is more efficient for the system to parse as well as reducing token count (I think)\n",
    "    - [ ] : Maybe using a different language model more targeted towards the context of a robotic system such as InstructGPT (although it is trained on smaller data sets)\n",
    "    - [ ] : Using the Microsoft seen way of asking chatGPT to call a sequence of functions and save that function, if successful instead of a task sequence. Thus reducing reaction time as well as decreasing the ammount of chatGPT calls.\n",
    "    - [ ] : And others that will be found either in the paper of the presentation or in the README of the github repository.\n",
    "- [ ] : The way this system is made makes it fairly user friendly to extend as long as you maintain a set of rules. Some of the possible extensions are:\n",
    "    - [ ] : Adding more acting modules to the system such as a module that can control a robotic arm or a module that can control a drone.\n",
    "    - [ ] : Adding more cognition modules to the system such as a module that can understand images and `point` for example (using chatGPT4) or a module that can understand audio.\n",
    "    - [ ] : Adding more decision making modules to the system such as a module that can understand the context of the conversation and make decisions based on that.\n",
    "    - [ ] : And others that will be found either in the paper of the presentation or in the README of the github repository.\n",
    "- [ ] : I hope that this presentation has given you a good overview of the ReAct system and I am open to any questions you might have."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Demo\n",
    "- Paper: Towards interactive robotics: Zero-shot action sequence generation using reasoning through ChatGPT\n",
    "- This system presents a take on a ReAct model (more info: https://react-lm.github.io/)\n",
    "- Creator: Andrei Dragomir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"fancy\" version of the system demo here.\n",
    "pip install tts\n",
    "follow this guide to plug in text-to-speech https://www.youtube.com/watch?v=MYRgWwis1Jk\n",
    "!! call tts with gpu=True to use gpu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system works on 3 forms of LLM conversations:\n",
    "\n",
    "Reasoning: Where the system reasons based on its information about the environment, activity logs or other information it has access to together with its general knowledge.\n",
    "\n",
    "When receiving a task to fulfill, generate goal_predicates.\n",
    "\n",
    "The thinking process behind fulfilling a task (called _end goal_) is as follows:\n",
    "- Step 1: Load knowledge about its own activity up until that point (not extremely detailed ones, just conclusions of thought processes)\n",
    "- Step 2: Define the next step to take based on the current state of the environment (Perceive, Reason, Act, Communicate)\n",
    "- Step 3: Load functionality for any of the type of actions.\n",
    "- Step 4: Call the functionality using chatGPT with the task goal being the goal defined at step 2.\n",
    "- Step 5: After the call completes, save the new state of the environment and the new activity log independent of the action's success.\n",
    "- Step 6: \n",
    "    - If the action was successful, check if the end goal was reached by evaluating goal predicates. \n",
    "    - Else, repeat from step 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import time\n",
    "from gpt_controller.config import *\n",
    "from gpt_controller.util.models import *\n",
    "from gpt_controller.util.labels import *\n",
    "from gpt_controller.cognition.machine import Machine\n",
    "\n",
    "machine = Machine(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulation\n",
    "\n",
    "- Limitations:\n",
    "  - Objects that have the attribute \"is_accessible\" set to true make the contained objects graspable.\n",
    "- Policy:\n",
    "  - To take an object from within another object you must recursively reach that object from the top most container object to the object that contains the required object.\n",
    "  - If any object in the sequence fails to be accessed, give context as to which object is not accessible and why."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception\n",
    "\n",
    "- Through perception you can find an object that you do not have yet in memory.\n",
    "- You can also do specific checks on objects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get prompt deck from the prompt directory as a dictionary\n",
    "# Returns a dictionary of prompt names and prompts\n",
    "def get_prompt_deck() -> dict[str, str]:\n",
    "    prompt_deck = {}\n",
    "    for root, dirs, files in os.walk(PROMPT_PATH):\n",
    "        for name in files:\n",
    "            if name.endswith(\".txt\"):\n",
    "                prompt_location = os.path.abspath(os.path.join(root, name))\n",
    "                try:\n",
    "                    with open(prompt_location, \"r\") as f:\n",
    "                        prompt = f.read()\n",
    "                        f.flush()\n",
    "                    prompt_deck[name] = prompt\n",
    "                except OSError as e:\n",
    "                    print(\"Error: Prompt {} could not be loaded with reason: {}\".format(name, e.args[0]))\n",
    "                    continue\n",
    "    return prompt_deck    \n",
    "        \n",
    "def num_tokens_prompt(prompt: str):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(CHATGPT_MODEL)\n",
    "    num_tokens = len(encoding.encode(prompt))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: decision_making.txt \n",
      "Number of tokens: 400\n",
      "\n",
      "Prompt: general_capabilities.txt \n",
      "Number of tokens: 101\n",
      "\n",
      "Prompt: label_input.txt \n",
      "Number of tokens: 62\n",
      "\n",
      "Prompt: memorize_object.txt \n",
      "Number of tokens: 253\n",
      "\n",
      "Prompt: function_similarity.txt \n",
      "Number of tokens: 199\n",
      "\n",
      "Prompt: get_goal_predicates.txt \n",
      "Number of tokens: 389\n",
      "\n",
      "Prompt: question_about_context.txt \n",
      "Number of tokens: 373\n",
      "\n",
      "Prompt: label_segment_input copy.txt \n",
      "Number of tokens: 289\n",
      "\n",
      "Prompt: segment_input.txt \n",
      "Number of tokens: 76\n",
      "\n",
      "Prompt: memorize_derivate_function.txt \n",
      "Number of tokens: 91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, prompt in get_prompt_deck().items():\n",
    "    num_tokens = num_tokens_prompt(prompt)\n",
    "    if num_tokens == 0:\n",
    "        continue\n",
    "    print(\"Prompt: {} \\nNumber of tokens: {}\\n\".format(name, num_tokens))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Targeted prompt tests\n",
    "\n",
    "- This section provides tests for specific prompts that are used in the system.\n",
    "- The tests are done by running the prompt through chatGPT and checking if the output is the expected one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labelling\n",
    "\n",
    "- You can make sets of prompts for a specific type of label and run them all at once using the helper function `run_label_tests()`.\n",
    "    - You must pass a list of strings that you want to test\n",
    "    - You must specify what label you want to test.\n",
    "    - The function returns an accuracy score of the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_label_tests(prompt_deck : list[tuple[Label, str]], expected_label : Label):\n",
    "    right_answers = 0\n",
    "    for label, prompt in prompt_deck:\n",
    "        provided_label = machine.label(prompt, expected_label.__class__)\n",
    "        time.sleep(2)\n",
    "        if provided_label == label:\n",
    "            right_answers += 1\n",
    "        else:\n",
    "            print(\"Prompt: {}\\nExpected Label: {}\\nProvided Label: {}\\n\".format(prompt, expected_label, provided_label))\n",
    "    return right_answers/len(prompt_deck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task type labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_set = [\n",
    "    \"Peel 5 potatoes.\",\n",
    "    \"Stir the pot of soup.\",\n",
    "    \"Chop onions.\",\n",
    "    \"Pour ingredients into a mixing bowl.\",\n",
    "    \"Wash fruits and vegetables.\",\n",
    "    \"Measure ingredients for the recipe.\",\n",
    "    \"Open the jar of jam.\",\n",
    "    \"Grate cheese.\",\n",
    "    \"Preheat the oven to a specific temperature.\",\n",
    "    \"Set a timer for cooking or baking.\",\n",
    "    \"Mix ingredients together in a bowl.\",\n",
    "    \"Slice some bread.\",\n",
    "    \"Pour liquids into containers.\",\n",
    "    \"Clean countertop with the sponge.\",\n",
    "    \"Load the dishwasher.\",\n",
    "    \"Retrieve items from cabinets or shelves.\",\n",
    "    \"Remove hot dishes from the oven.\",\n",
    "    \"Garnish plates with herbs or sauces.\",\n",
    "    \"Arrange food on a serving platter.\",\n",
    "    \"Brew a cup of coffee or tea.\",\n",
    "    \"Clean kitchen utensils.\",\n",
    "    \"Wipe spills from the floor.\",\n",
    "    \"Refill water bottles or containers.\",\n",
    "    \"Organize pantry items.\",\n",
    "    \"Dispose of food waste.\"\n",
    "]\n",
    "\n",
    "\n",
    "labelled_task_set = [(UserInputLabel.TASK, prompt) for prompt in task_set]\n",
    "\n",
    "run_label_tests(labelled_task_set, UserInputLabel.TASK)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated task labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Recall any knowledge about the location of the ingredients.\n",
      "Label: TaskLabel.COGNITION\n",
      "\n",
      "Prompt: Move to the refrigerator.\n",
      "Label: TaskLabel.NAVIGATION\n",
      "\n",
      "Prompt: Open the fridge\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Find vegetables for the salad.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Pick up a tomato\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Place it on the counter.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Pick up a cucumber.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Place it on the counter.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Pick up a lettuce.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Place it on the counter.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Close the refrigerator.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "\u001b[31mError: Getting completion (1/3) failed with reason: The server is overloaded or not ready yet.\n",
      "\u001b[0m\n",
      "Prompt: Move to the counter.\n",
      "Label: TaskLabel.NAVIGATION\n",
      "\n",
      "Prompt: Find a knife.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Ask where the knife could be located.\n",
      "Label: TaskLabel.INQUIRY\n",
      "\n",
      "Prompt: Pick up the knife.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Slice the vegetables.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Which vegetable should be sliced first?\n",
      "Label: TaskLabel.INQUIRY\n",
      "\n",
      "Prompt: Slice the tomato.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Slice the cucumber.\n",
      "Label: TaskLabel.MANIPULATION\n",
      "\n",
      "Prompt: Move to the sink.\n",
      "Label: TaskLabel.NAVIGATION\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_topic = \"Make a salad\"\n",
    "\n",
    "task_sequence = [\n",
    "    \"Recall any knowledge about the location of the ingredients.\",\n",
    "    \"Move to the refrigerator.\",\n",
    "    \"Open the fridge\",\n",
    "    \"Look for vegetables for the salad.\",\n",
    "    \"Pick up a tomato\",\n",
    "    \"Place it on the counter.\",\n",
    "    \"Pick up a cucumber.\",\n",
    "    \"Place it on the counter.\",\n",
    "    \"Pick up a lettuce.\",\n",
    "    \"Place it on the counter.\",\n",
    "    \"Close the refrigerator.\",\n",
    "    \"Move to the counter.\",\n",
    "    \"Find a knife.\",\n",
    "    \"Ask where the knife could be located.\",\n",
    "    \"Pick up the knife.\",\n",
    "    \"Slice the vegetables.\",\n",
    "    \"Which vegetable should be sliced first?\",\n",
    "    \"Slice the tomato.\",\n",
    "    \"Slice the cucumber.\",\n",
    "    \"Move to the sink.\"\n",
    "]\n",
    "\n",
    "for prompt in task_sequence:\n",
    "    label = machine.label(prompt, TaskLabel)\n",
    "    print(\"Prompt: {}\\nLabel: {}\\n\".format(prompt, label))\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User input segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a phrase splitting algorithm.\n",
      "The user will give you a text input, and you will return a list of simple sentences derived from segmenting the input from the user.\n",
      "The sentences should be understandable isolated so wherever pronouns are used to describe an object, replace the pronouns with the name of the object.\n",
      "You must return a list of sentences in a form that is parsable in python into a list.\n",
      "You must only return the splitting list, no prose.\n",
      "\n",
      "Here's a general approach to this process:\n",
      "\n",
      "1. Identify the main clause: Determine the main clause or the central part of the sentence that expresses a complete thought.\n",
      "2. Look for coordinating conjunctions: Identify any coordinating conjunctions (such as \"and,\" \"but,\" \"or,\" etc.) that can be used to divide the sentence into separate clauses.\n",
      "3. Identify subordinating clauses: Identify any subordinating clauses (such as those introduced by words like \"because,\" \"although,\" \"if,\" etc.) that can be treated as separate sentences or combined with the main clause to form simpler sentences.\n",
      "4. Locate punctuation marks: Observe the presence of punctuation marks like periods, question marks, or exclamation marks, which often indicate natural sentence breaks.\n",
      "5. Consider meaning and clarity: Ensure that the resulting sentences convey clear and coherent meaning when divided. Adjust the sentence structure or phrasing as needed.\n",
      "6. Review grammar and syntax: Check that each resulting sentence adheres to proper grammar and sentence structure rules.\n",
      "\n",
      "Example:\n",
      "```\n",
      "Input: \"Give me the tomato and then open the fridge. At the end, you should give me any food you find but do not give me a tomato.\"\n",
      "Output: [\"Give me the tomato\", \"Open the fridge\", \"At the end, you should give me any food you find.\", \"Do not give me a tomato\"]\n",
      "```\n",
      "\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Tell me what color the fork has\\nTell me what color the knife has\\nYou should only use your cognitive abilities, without perceiving the environment to extract data\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "input_string = '''Tell me what color the fork has then tell me what color the knife has. You should only use your cognitive abilities, without perceiving the environment to extract data'''\n",
    "\n",
    "conversation = Conversation(ConversationType.LABELLING)\n",
    "conversation.messages.append(Message(Role.SYSTEM, machine.load_prompt('segment_input.txt')))\n",
    "conversation.messages.append(Message(Role.USER, input_string))\n",
    "\n",
    "completion = machine.process(conversation.messages)\n",
    "print(completion['content'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal predicate generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementing a ReAct system for interfacing with chatGPT\n",
    "    - ReAct is a system that allows for the generation of actions from a given state.\n",
    "    - It is a system that is trained on a dataset of actions and states.\n",
    "\n",
    "    **Inspiration**\n",
    "    https://react-lm.github.io/\n",
    "\n",
    "- Implement defensive json parsing for the chatGPT system\n",
    "    - Use a json schema to validate the input json\n",
    "    - Use a library like `Langchain` or `llmparser` to recover from slightly malformed json outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-controller-pQPBvhTj-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
