{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Demo\n",
    "- Paper: Towards interactive robotics: Zero-shot action sequence generation using reasoning through ChatGPT\n",
    "- This system presents a take on a ReAct model (more info: https://react-lm.github.io/)\n",
    "- Creator: Andrei Dragomir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \"fancy\" version of the system demo here.\n",
    "pip install tts\n",
    "follow this guide to plug in text-to-speech https://www.youtube.com/watch?v=MYRgWwis1Jk\n",
    "!! call tts with gpu=True to use gpu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import time\n",
    "from gpt_controller.config import *\n",
    "from gpt_controller.util.models import *\n",
    "from gpt_controller.util.labels import *\n",
    "from gpt_controller.cognition.machine import Machine\n",
    "\n",
    "machine = Machine(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing chatGPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get prompt deck from the prompt directory as a dictionary\n",
    "# Returns a dictionary of prompt names and prompts\n",
    "def get_prompt_deck() -> dict[str, str]:\n",
    "    prompt_deck = {}\n",
    "    for root, dirs, files in os.walk(PROMPT_PATH):\n",
    "        for name in files:\n",
    "            if name.endswith(\".txt\"):\n",
    "                prompt_location = os.path.abspath(os.path.join(root, name))\n",
    "                try:\n",
    "                    with open(prompt_location, \"r\") as f:\n",
    "                        prompt = f.read()\n",
    "                        f.flush()\n",
    "                    prompt_deck[name] = prompt\n",
    "                except OSError as e:\n",
    "                    print(\"Error: Prompt {} could not be loaded with reason: {}\".format(name, e.args[0]))\n",
    "                    continue\n",
    "    return prompt_deck    \n",
    "        \n",
    "def num_tokens_prompt(prompt: str):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(CHATGPT_MODEL)\n",
    "    num_tokens = len(encoding.encode(prompt))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, prompt in get_prompt_deck().items():\n",
    "    num_tokens = num_tokens_prompt(prompt)\n",
    "    if num_tokens == 0:\n",
    "        continue\n",
    "    print(\"Prompt: {} \\nNumber of tokens: {}\\n\".format(name, num_tokens))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Targeted prompt tests\n",
    "\n",
    "- This section provides tests for specific prompts that are used in the system.\n",
    "- The tests are done by running the prompt through chatGPT and checking if the output is the expected one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labelling\n",
    "\n",
    "- You can make sets of prompts for a specific type of label and run them all at once using the helper function `run_label_tests()`.\n",
    "    - You must pass a list of strings that you want to test\n",
    "    - You must specify what label you want to test.\n",
    "    - The function returns an accuracy score of the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_label_tests(prompt_deck : list[tuple[Label, str]], expected_label : Label):\n",
    "    right_answers = 0\n",
    "    for label, prompt in prompt_deck:\n",
    "        provided_label = machine.label(prompt, expected_label.__class__)\n",
    "        time.sleep(2)\n",
    "        if provided_label == label:\n",
    "            right_answers += 1\n",
    "        else:\n",
    "            print(\"Prompt: {}\\nExpected Label: {}\\nProvided Label: {}\\n\".format(prompt, expected_label, provided_label))\n",
    "    return right_answers/len(prompt_deck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task type labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_set = [\n",
    "    \"Peel 5 potatoes.\",\n",
    "    \"Stir the pot of soup.\",\n",
    "    \"Chop onions.\",\n",
    "    \"Pour ingredients into a mixing bowl.\",\n",
    "    \"Wash fruits and vegetables.\",\n",
    "    \"Measure ingredients for the recipe.\",\n",
    "    \"Open the jar of jam.\",\n",
    "    \"Grate cheese.\",\n",
    "    \"Preheat the oven to a specific temperature.\",\n",
    "    \"Set a timer for cooking or baking.\",\n",
    "    \"Mix ingredients together in a bowl.\",\n",
    "    \"Slice some bread.\",\n",
    "    \"Pour liquids into containers.\",\n",
    "    \"Clean countertop with the sponge.\",\n",
    "    \"Load the dishwasher.\",\n",
    "    \"Retrieve items from cabinets or shelves.\",\n",
    "    \"Remove hot dishes from the oven.\",\n",
    "    \"Garnish plates with herbs or sauces.\",\n",
    "    \"Arrange food on a serving platter.\",\n",
    "    \"Brew a cup of coffee or tea.\",\n",
    "    \"Clean kitchen utensils.\",\n",
    "    \"Wipe spills from the floor.\",\n",
    "    \"Refill water bottles or containers.\",\n",
    "    \"Organize pantry items.\",\n",
    "    \"Dispose of food waste.\"\n",
    "]\n",
    "\n",
    "\n",
    "labelled_task_set = [(UserInputLabel.TASK, prompt) for prompt in task_set]\n",
    "\n",
    "run_label_tests(labelled_task_set, UserInputLabel.TASK)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated task labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_topic = \"Make a salad\"\n",
    "\n",
    "task_sequence = [\n",
    "    \"Recall any knowledge about the location of the ingredients.\",\n",
    "    \"Move to the refrigerator.\",\n",
    "    \"Open the fridge\",\n",
    "    \"Look for vegetables for the salad.\",\n",
    "    \"Pick up a tomato\",\n",
    "    \"Place it on the counter.\",\n",
    "    \"Pick up a cucumber.\",\n",
    "    \"Place it on the counter.\",\n",
    "    \"Pick up a lettuce.\",\n",
    "    \"Place it on the counter.\",\n",
    "    \"Close the refrigerator.\",\n",
    "    \"Move to the counter.\",\n",
    "    \"Find a knife.\",\n",
    "    \"Ask where the knife could be located.\",\n",
    "    \"Pick up the knife.\",\n",
    "    \"Slice the vegetables.\",\n",
    "    \"Which vegetable should be sliced first?\",\n",
    "    \"Slice the tomato.\",\n",
    "    \"Slice the cucumber.\",\n",
    "    \"Move to the sink.\"\n",
    "]\n",
    "\n",
    "for prompt in task_sequence:\n",
    "    label = machine.label(prompt, TaskLabel)\n",
    "    print(\"Prompt: {}\\nLabel: {}\\n\".format(prompt, label))\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User input segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = '''Tell me what color the fork has then tell me what color the knife has. You should only use your cognitive abilities, without perceiving the environment to extract data'''\n",
    "\n",
    "conversation = Conversation(ConversationType.LABELLING)\n",
    "conversation.messages.append(Message(Role.SYSTEM, machine.load_prompt('segment_input.txt')))\n",
    "conversation.messages.append(Message(Role.USER, input_string))\n",
    "\n",
    "completion = machine.process(conversation.messages)\n",
    "print(completion['content'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementing a ReAct system for interfacing with chatGPT\n",
    "    - ReAct is a system that allows for the generation of actions from a given state.\n",
    "    - It is a system that is trained on a dataset of actions and states.\n",
    "\n",
    "    **Inspiration**\n",
    "    https://react-lm.github.io/\n",
    "\n",
    "- Implement defensive json parsing for the chatGPT system\n",
    "    - Use a json schema to validate the input json\n",
    "    - Use a library like `Langchain` or `llmparser` to recover from slightly malformed json outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-controller-pQPBvhTj-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
